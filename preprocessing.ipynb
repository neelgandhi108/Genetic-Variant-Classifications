{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP 5\n",
    "# Neel Gandhi, Sunishka Jain, Daniel Shen, Julian Wu\n",
    "\n",
    "## PREPROCESSING\n",
    "### This notebook takes in the raw data from 'clinvar_conflicting.csv'\n",
    "### and processes all the data, reducing our feature count to 54\n",
    "### and numericizing every cell value\n",
    "\n",
    "## OUTPUT\n",
    "### A processed csv file will be created, called 'processedData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fractions import Fraction\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "file = './clinvar_conflicting.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "MM0574ZC3L4B",
    "outputId": "1bd1983e-7c0c-47a5-c2c7-bce86215017f"
   },
   "outputs": [],
   "source": [
    "# This is code to create an initial correlation matrix\n",
    "# We are not depicting this matrix in our paper\n",
    "\n",
    "corr_matrix = data.corr()\n",
    "# print(corr_matrix)\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDDBEPhQUgxN",
    "outputId": "aa7ff46f-a0d2-4eaa-b153-243d3856842d"
   },
   "outputs": [],
   "source": [
    "# Processing 'CHROM' column\n",
    "\n",
    "data.loc[:, 'CHROM'].replace('X', 23, inplace=True)\n",
    "data.loc[:, 'CHROM'].replace('MT', 24, inplace=True)\n",
    "data.loc[:, 'CHROM'] = data.CHROM.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkPV2Qs7VH2p",
    "outputId": "a299a535-cc06-4c5a-fa4e-5fceb325cbb3"
   },
   "outputs": [],
   "source": [
    "# Processing 'REF' column\n",
    "\n",
    "data.loc[data['REF'] == \"A\", \"REF\"] = 1\n",
    "data.loc[data['REF'] == \"T\", \"REF\"] = 2\n",
    "data.loc[data['REF'] == \"G\", \"REF\"] = 3\n",
    "data.loc[data['REF'] == \"C\", \"REF\"] = 4\n",
    "all_other_values = data.loc[:, 'REF'].unique()\n",
    "all_other_value_map = {}\n",
    "\n",
    "for i in range(len(all_other_values)):\n",
    "  all_other_value_map[all_other_values[i]] = 5 \n",
    "\n",
    "rem_list = [1,2,3,4]\n",
    "for key in rem_list:\n",
    "    del all_other_value_map[key]\n",
    "\n",
    "data['REF'] = data['REF'].replace(all_other_value_map)\n",
    "\n",
    "# data['REF'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vn60OVXPrXBg",
    "outputId": "b78c57cd-462e-4e52-f83b-4750fe7c091b"
   },
   "outputs": [],
   "source": [
    "# Processing 'ALT' column\n",
    "\n",
    "data.loc[data['ALT'] == \"A\", \"ALT\"] = 1\n",
    "data.loc[data['ALT'] == \"T\", \"ALT\"] = 2\n",
    "data.loc[data['ALT'] == \"G\", \"ALT\"] = 3\n",
    "data.loc[data['ALT'] == \"C\", \"ALT\"] = 4\n",
    "\n",
    "all_other_values = data.loc[:, 'ALT'].unique()\n",
    "all_other_value_map = {}\n",
    "for i in range(len(all_other_values)):\n",
    "  all_other_value_map[all_other_values[i]] = 5 \n",
    "\n",
    "rem_list = [1,2,3,4]\n",
    "for key in rem_list:\n",
    "    del all_other_value_map[key]\n",
    "\n",
    "data['ALT'] = data['ALT'].replace(all_other_value_map)\n",
    "\n",
    "# data['ALT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKCvpmrI3L4B",
    "outputId": "a7063418-2c33-4ac6-dc9b-166d77a74df4"
   },
   "outputs": [],
   "source": [
    "# Processing 'CLNVC' column into one-hot encoded variables for the different variant types\n",
    "\n",
    "data.loc[data['CLNVC'] == \"single_nucleotide_variant\", \"CLNVC\"] = 0\n",
    "data.loc[data['CLNVC'] == \"Deletion\", \"CLNVC\"] = 1\n",
    "data.loc[data['CLNVC'] == \"Duplication\", \"CLNVC\"] = 2\n",
    "data.loc[data['CLNVC'] == \"Indel\", \"CLNVC\"] = 3\n",
    "data.loc[data['CLNVC'] == \"Inversion\", \"CLNVC\"] = 4\n",
    "data.loc[data['CLNVC'] == \"Insertion\", \"CLNVC\"] = 5\n",
    "data.loc[data['CLNVC'] == \"Microsatellite\", \"CLNVC\"] = 6\n",
    "\n",
    "data['CLNVC'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCT8sOSg3L4B",
    "outputId": "ad8a553e-80e9-4300-f1dd-ace785b22cb9"
   },
   "outputs": [],
   "source": [
    "# Processing 'IMPACT' column into dummy variables\n",
    "\n",
    "data.loc[data['IMPACT'] == \"MODERATE\", \"IMPACT\"] = 0\n",
    "data.loc[data['IMPACT'] == \"MODIFIER\", \"IMPACT\"] = 1\n",
    "data.loc[data['IMPACT'] == \"LOW\", \"IMPACT\"] = 2\n",
    "data.loc[data['IMPACT'] == \"HIGH\", \"IMPACT\"] = 3\n",
    "\n",
    "data['IMPACT'] = data['IMPACT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEhNpOmhkLMu"
   },
   "outputs": [],
   "source": [
    "# Processing 'PolyPhen' and 'SIFT' columns into dummy variables\n",
    "\n",
    "data['PolyPhen'] = data['PolyPhen'].replace({'benign':1, 'probably_damaging':2, 'possibly_damaging' : 3})\n",
    "data['PolyPhen'] = pd.to_numeric(data['PolyPhen'], errors='coerce').fillna(0, downcast='infer')\n",
    "data['SIFT'] = data['SIFT'].replace({'tolerated':1, 'deleterious_low_confidence':2, 'deleterious' : 3})\n",
    "data['SIFT'] = pd.to_numeric(data['SIFT'], errors='coerce').fillna(0, downcast='infer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "69W9wBWWe-DV",
    "outputId": "fdaa73a0-e871-4001-cd81-55ea3be2004b"
   },
   "outputs": [],
   "source": [
    "# Processing 'Amino_Acids' column into numerical values\n",
    "\n",
    "Amino_acid_type = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y','*','-']\n",
    "Amino_acid_value_map = {}\n",
    "for i in range(len(Amino_acid_type)):\n",
    "  Amino_acid_value_map[Amino_acid_type[i]] = i+1\n",
    "\n",
    "Amino_acid_ref = data['Amino_acids'].str.split(\"/\", n=-1, expand=False).str[0]\n",
    "Amino_acid_alt = data['Amino_acids'].str.split(\"/\", n=-1, expand=False).str[1]\n",
    "\n",
    "Amino_acid_ref = Amino_acid_ref.replace(Amino_acid_value_map)\n",
    "Amino_acid_alt = Amino_acid_alt.replace(Amino_acid_value_map)\n",
    "\n",
    "Amino_acid_ref = pd.to_numeric(Amino_acid_ref, errors='coerce').fillna(24, downcast='infer')\n",
    "Amino_acid_alt = pd.to_numeric(Amino_acid_alt, errors='coerce').fillna(24, downcast='infer')\n",
    "\n",
    "\n",
    "data['AA_REF'] = Amino_acid_ref \n",
    "data['AA_ALT'] = Amino_acid_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lis3V0D05Zp"
   },
   "outputs": [],
   "source": [
    "# DataFrame for BLOSUM62 table which is symmetric diagonally\n",
    "\n",
    "dataBLOSUM62 = [[4, 0, -2, -1, -2, 0, -2, -1, -1, -1, -1, -2, -1, -1, -1, 1, 0, 0, -3, -2], \n",
    "                [0, 9, -3, -4, -2, -3, -3, -1, -3, -1, -1, -3, -3, -3, -3, -1, -1, -1, -2, -2], \n",
    "                [-2, -3, 6, 2, -3, -1, -1, -3, -1, -4, -3, 1, -1, 0, -2, 0, -1, -3, -4, -3], \n",
    "                [-1, -4, 2, 5, -3, -2, 0, -3, 1, -3, -2, 0, -1, 2, 0, 0, -1, -2, -3, -2], \n",
    "                [-2, -2, -3, -3, 6, -3, -1, 0, -3, 0, 0, -3, -4, -3, -3, -2, -2, -1, 1, 3], \n",
    "                [0, -3, -1, -2, -3, 6, -2, -4, -2, -4, -3, 0, -2, -2, -2, 0, -2, -3, -2, -3], \n",
    "                [-2, -3, -1, 0, -1, -2, 8, -3, -1, -3, -2, 1, -2, 0, 0, -1, -2, -3, -2, 2], \n",
    "                [-1, -1, -3, -3, 0, -4, -3, 4, -3, 2, 1, -3, -3, -3, -3, -2, -1, 3, -3, -1], \n",
    "                [-1, -3, -1, 1, -3, -2, -1, -3, 5, -2, -1, 0, -1, 1, 2, 0, -1, -2, -3, -2], \n",
    "                [-1, -1, -4, -3, 0, -4, -3, 2, -2, 4, 2, -3, -3, -2, -2, -2, -1, 1, -2, -1], \n",
    "                [-1, -1, -3, -2, 0, -3, -2, 1, -1, 2, 5, -2, -2, 0, -1, -1, -1, 1, -1, -1], \n",
    "                [-2, -3, 1, 0, -3, 0, 1, -3, 0, -3, -2, 6, -2, 0, 0, 1, 0, -3, -4, -2], \n",
    "                [-1, -3, -1, -1, -4, -2, -2, -3, -1, -3, -2, -2, 7, -1, -2, -1, -1, -2, -4, -3], \n",
    "                [-1, -3, 0, 2, -3, -2, 0, -3, 1, -2, 0, 0, -1, 5, 1, 0, -1, -2, -2, -1], \n",
    "                [-1, -3, -2, 0, -3, -2, 0, -3, 2, -2, -1, 0, -2, 1, 5, -1, -1, -3, -3, -2], \n",
    "                [1, -1, 0, 0, -2, 0, -1, -2, 0, -2, -1, 1, -1, 0, -1, 4, 1, -2, -3, -2], \n",
    "                [0, -1, -1, -1, -2, -2, -2, -1, -1, -1, -1, 0, -1, -1, -1, 1, 5, 0, -2, -2], \n",
    "                [0, -1, -3, -2, -1, -3, -3, 3, -2, 1, 1, -3, -2, -2, -3, -2, 0, 4, -3, -1], \n",
    "                [-3, -2, -4, -3, 1, -2, -2, -3, -3, -2, -1, -4, -4, -2, -3, -3, -2, -3, 11, 2], \n",
    "                [-2, -2, -3, -2, 3, -3, 2, -1, -2, -1, -1, -2, -3, -1, -2, -2, -2, -1, 2, 7]]\n",
    "\n",
    "df_BLOSUM62 = pd.DataFrame(dataBLOSUM62, \n",
    "        columns=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], \n",
    "        index = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrHGM1jp1A8I"
   },
   "outputs": [],
   "source": [
    "# Function used for column 'ORIGIN' in order to classify\n",
    "# each value into one-hot encoded origin types.\n",
    "# Used in the cell below.\n",
    "\n",
    "def get_power_list(num):\n",
    "  ans = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  max_power = 9\n",
    "\n",
    "  if num == 1073741824:\n",
    "    ans[11] = 1\n",
    "\n",
    "  elif num == 0:\n",
    "    ans[0] = 1\n",
    "\n",
    "  else:\n",
    "    current_power = max_power\n",
    "    while current_power >= 0:\n",
    "      value = 2 ** current_power\n",
    "      if num >= value:\n",
    "        num -= value\n",
    "        ans[current_power+1] = 1\n",
    "      current_power -= 1\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsmuW-jZ1G8o"
   },
   "outputs": [],
   "source": [
    "# Processing 'ORIGIN' column into one-hot encoded variables for each origin type\n",
    "\n",
    "origin = pd.DataFrame()\n",
    "origin['collective_list'] = data['ORIGIN'].apply(lambda x: get_power_list(x))\n",
    "\n",
    "origin[['unknown_Origin','germline_Origin','somatic_Origin','inherited_Origin','paternal_Origin',\n",
    "        'maternal_Origin','de-novo_Origin','biparental_Origin','uniparental_Origin','not-tested_Origin',\n",
    "        'inconclusive_Origin','other_Origin']] = pd.DataFrame(\n",
    "            origin.collective_list.tolist(), index= origin.index)\n",
    "\n",
    "data = data.join(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdcNdoFh1HoT"
   },
   "outputs": [],
   "source": [
    "# Function used for column 'MC' in order to classify\n",
    "# each value into one-hot encoded variant types.\n",
    "# Used in the cell below.\n",
    "\n",
    "def get_variant_list(myList):\n",
    "  ans = [0,0,0]\n",
    "\n",
    "  if str(myList) == 'nan':\n",
    "    return ans\n",
    "\n",
    "  for variant in myList:\n",
    "    var_str = variant.split('|')[1]\n",
    "    if var_str == 'missense_variant':\n",
    "      ans[0] = 1\n",
    "    elif var_str == 'synonymous_variant':\n",
    "      ans[1] = 1\n",
    "    else:\n",
    "      ans[2] = 1\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQxkDM2l1MCs"
   },
   "outputs": [],
   "source": [
    "# Processing 'MC' column into one-hot encoded variables\n",
    "# for the top 3 different variant types\n",
    "\n",
    "consequences = pd.DataFrame()\n",
    "\n",
    "consequences['MC'] = data['MC'].str.split(\",\", n = -1, expand = False)\n",
    "consequences['variantList'] = consequences['MC'].apply(lambda x: get_variant_list(x))\n",
    "consequences[['missense_Variant','synonymous_Variant','other_Variant']] = pd.DataFrame(\n",
    "            consequences.variantList.tolist(), index= consequences.index)\n",
    "\n",
    "# print(consequences)\n",
    "missense_col = consequences['missense_Variant']\n",
    "synonymous_col = consequences['synonymous_Variant']\n",
    "other_col = consequences['other_Variant']\n",
    "\n",
    "data = data.join(missense_col)\n",
    "data = data.join(synonymous_col)\n",
    "data = data.join(other_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processeing 'SYMBOL' column into dummy variables for the SYMBOL feature, which are just the names of the genes \n",
    "\n",
    "gene_names = data['SYMBOL'].unique()\n",
    "\n",
    "#Arbitrarily assigning each of the 2329 genes to a number\n",
    "for i in range(0, len(gene_names)):\n",
    "    data.loc[data['SYMBOL'] == gene_names[i], \"SYMBOL\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing 'EXON' column, which shows fractions (exon #/total #)\n",
    "\n",
    "exon_locations = data['EXON'].unique()\n",
    "\n",
    "# Converting all the unique string forms of the fractions into floats \n",
    "\n",
    "for i in range(0, len(exon_locations)):\n",
    "    # Pass the NaNs because we will drop rows that contain NaNs later\n",
    "    if(isinstance(exon_locations[i], float)):\n",
    "        pass\n",
    "    else:\n",
    "        data.loc[data['EXON'] == exon_locations[i], \"EXON\"] = float(Fraction(exon_locations[i]))\n",
    "        \n",
    "float_exon_locations = data['EXON'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing 'INTRON' column -- same concept as EXONS above\n",
    "\n",
    "intron_locations = data['INTRON'].unique()\n",
    "\n",
    "# Converting all the unique string forms of the fractions into floats \n",
    "for i in range(0, len(intron_locations)):\n",
    "    # Pass the NaNs because we will drop rows that contain NaNs later\n",
    "    if(isinstance(intron_locations[i], float)):\n",
    "        pass\n",
    "    else:\n",
    "        data.loc[data['INTRON'] == intron_locations[i], \"INTRON\"] = float(Fraction(intron_locations[i]))\n",
    "        \n",
    "float_intron_locations = data['INTRON'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['INTRON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the INTRON and EXON features above, we will create two additional columns:\n",
    "# 'IE': denoted as 0/1\n",
    "# 'IE_Loc\": location within the intron and exon\n",
    "\n",
    "# First tackling the binary of INTRON vs. EXON as a new column\n",
    "IE_binary = []\n",
    "IE_location = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # For some reason this condition is not being met :/\n",
    "    if pd.isnull(row['EXON']):\n",
    "        IE_binary.append(0)\n",
    "        IE_location.append(row['INTRON'])\n",
    "    # Exon\n",
    "    else:\n",
    "        IE_binary.append(1)\n",
    "        IE_location.append(row['EXON'])\n",
    "\n",
    "# Now adding these two additional columns into the dataframe\n",
    "data['IE'] = IE_binary\n",
    "data['IE_Loc'] = IE_location\n",
    "data['IE'] = data['IE'].astype(int)\n",
    "data['IE_Loc'] = data['IE_Loc'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Intron and Exon columns because of the 2 new columns we created\n",
    "data.drop('INTRON', inplace=True, axis=1)\n",
    "data.drop('EXON', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing 'CLNDN' column into one-hot encoded variables for each possible disease consequence\n",
    "\n",
    "col9 = data[\"CLNDN\"]\n",
    "col9Types = {}\n",
    "\n",
    "# Find every type of disease consequence\n",
    "for s in col9:\n",
    "    s = str(s)\n",
    "    types = s.split('|')\n",
    "    for type in types:\n",
    "        if type in col9Types:\n",
    "            col9Types[type] += 1\n",
    "        else:\n",
    "            col9Types[type] = 1\n",
    "\n",
    "# Taking only the top N values, excluding 'not_specified' and 'not_found'\n",
    "topN = 15\n",
    "topNTypes = dict(sorted(col9Types.items(), key = itemgetter(1), reverse = True)[:(topN + 2)])\n",
    "topNTypes.pop('not_specified')\n",
    "topNTypes.pop('not_provided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the top N disease consequences to the dataframe\n",
    "\n",
    "for type in topNTypes.keys():\n",
    "    data[\"has_\" + type] = 0\n",
    "\n",
    "for i in range(len(col9)):\n",
    "    types = str(col9[i]).split('|')\n",
    "    for type in types:\n",
    "        if type in topNTypes.keys():\n",
    "            data.at[i, \"has_\" + type] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['CLNDISDB', 'CLNDISDBINCL', 'CLNDN', 'CLNDNINCL', 'CLNHGVS', \n",
    "                    'CLNSIGINCL', 'CLNVI', 'MC', 'ORIGIN', 'SSR', 'Allele',\n",
    "                    'Consequence', 'Feature_type', 'Feature', 'BIOTYPE',\n",
    "                    'Codons', 'DISTANCE', 'BAM_EDIT',\n",
    "                    'MOTIF_NAME', 'MOTIF_POS', 'HIGH_INF_POS', 'MOTIF_SCORE_CHANGE'])\n",
    "\n",
    "# Drop 2 more columns!\n",
    "data = data.drop(columns=\"BLOSUM62\") # dropping BLOSUM62 score FOR NOW\n",
    "data = data.drop(columns='Amino_acids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at missing data of the resulting columns\n",
    "num_missing = data.isnull().sum()\n",
    "percentage_missing = data.isnull().sum().apply(lambda x: x/data.shape[0]*100)\n",
    "missing_data = pd.DataFrame({'Number of Missing':  num_missing,\n",
    "                             'Percentage of Missing': percentage_missing})\n",
    "\n",
    "missing_data['Percentage of Missing'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "print(\"BEFORE dropping missing data: \" + str(len(data)))\n",
    "data = data.dropna()\n",
    "print(\"AFTER dropping missing data: \" + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and clean up df\n",
    "data.rename(columns={\"cDNA_position\": \"cDNA_Pos\",\n",
    "                    \"CDS_position\": \"CDS_Pos\",\n",
    "                    \"Protein_position\": \"Protein_Pos\"               \n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved processed data to output file named 'processedData'\n",
    "data.to_csv('./processedData.csv')\n",
    "# print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "311f9256461ac280b82068fc725a24d611a5a83d3e4a2766e048ca4852818f88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
